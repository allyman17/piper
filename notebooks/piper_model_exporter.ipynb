{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"ffc800\"> **[Piper](https://github.com/rhasspy/piper) model exporter.**\n",
        "## ![Piper logo](https://contribute.rhasspy.org/img/logo.png)\n",
        "---\n",
        "\n",
        "* Original notebook by: [rmcpantoja](http://github.com/rmcpantoja)\n",
        "* Collaborator: [Xx_Nessu_xX](http://github.com/XxNessuxX)\n",
        "* Fork maintained by: [allyman17](https://github.com/allyman17/piper)"
      ],
      "metadata": {
        "id": "EOL-kjplZYEU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GPUVerification"
      },
      "outputs": [],
      "source": [
        "#@markdown # <font color=\"ffc800\"> **Verify GPU availability.** üñ•Ô∏è\n",
        "#@markdown ---\n",
        "#@markdown Run this cell first to ensure you have GPU access. ONNX export will be significantly slower on CPU.\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def check_gpu():\n",
        "    print(\"\\033[93m\" + \"=\"*50)\n",
        "    print(\"GPU VERIFICATION\")\n",
        "    print(\"=\"*50 + \"\\033[0m\\n\")\n",
        "    \n",
        "    # Check CUDA availability via nvidia-smi\n",
        "    try:\n",
        "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.free,driver_version', '--format=csv,noheader'],\n",
        "                                capture_output=True, text=True, timeout=10)\n",
        "        if result.returncode == 0 and result.stdout.strip():\n",
        "            gpu_info = result.stdout.strip().split(', ')\n",
        "            print(f\"\\033[92m‚úì GPU detected!\\033[0m\")\n",
        "            print(f\"  ‚Ä¢ Name: {gpu_info[0]}\")\n",
        "            print(f\"  ‚Ä¢ Total memory: {gpu_info[1]}\")\n",
        "            print(f\"  ‚Ä¢ Free memory: {gpu_info[2]}\")\n",
        "            print(f\"  ‚Ä¢ Driver version: {gpu_info[3]}\")\n",
        "            \n",
        "            # Additional PyTorch CUDA check\n",
        "            try:\n",
        "                import torch\n",
        "                if torch.cuda.is_available():\n",
        "                    print(f\"\\n\\033[92m‚úì PyTorch CUDA support: Available\\033[0m\")\n",
        "                    print(f\"  ‚Ä¢ CUDA version: {torch.version.cuda}\")\n",
        "                else:\n",
        "                    print(f\"\\n\\033[93m‚ö† PyTorch installed but CUDA not available yet.\\033[0m\")\n",
        "                    print(\"  This is normal before running the install cell.\")\n",
        "            except ImportError:\n",
        "                print(f\"\\n\\033[93m‚Ñπ PyTorch not yet installed - run the install cell next.\\033[0m\")\n",
        "            \n",
        "            print(\"\\n\\033[92m\" + \"=\"*50)\n",
        "            print(\"Ready to proceed! Run the install cell next.\")\n",
        "            print(\"=\"*50 + \"\\033[0m\")\n",
        "            return True\n",
        "        else:\n",
        "            raise Exception(\"No GPU found\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\033[91m‚úó No GPU detected!\\033[0m\")\n",
        "        print(f\"\\n\\033[93mTo enable GPU in Colab:\\033[0m\")\n",
        "        print(\"  1. Go to Runtime ‚Üí Change runtime type\")\n",
        "        print(\"  2. Select 'T4 GPU' under Hardware accelerator\")\n",
        "        print(\"  3. Click Save and wait for the runtime to restart\")\n",
        "        print(\"  4. Re-run this cell to verify\")\n",
        "        print(\"\\n\\033[91m\" + \"=\"*50)\n",
        "        print(\"‚ö† Export will be VERY slow without GPU!\")\n",
        "        print(\"=\"*50 + \"\\033[0m\")\n",
        "        return False\n",
        "\n",
        "gpu_available = check_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FfMKr8v2RVOm"
      },
      "outputs": [],
      "source": [
        "#@markdown # <font color=\"ffc800\"> **Install software.** üì¶\n",
        "#@markdown ---\n",
        "\n",
        "print(\"\\033[93mInstalling...\")\n",
        "%cd /content\n",
        "!git clone -q https://github.com/rhasspy/piper\n",
        "%cd /content/piper/src/python\n",
        "!pip install -q pip==24.0\n",
        "!pip install -q cython>=0.29.0 librosa>=0.9.2 numpy>=1.19.0 pytorch-lightning~=1.7.0 torch==1.13.1\n",
        "!pip install -q onnx onnxruntime-gpu\n",
        "!bash build_monotonic_align.sh\n",
        "!pip install -q torchtext==0.14.1\n",
        "# fixing recent compatibility issues:\n",
        "!pip install -q torchaudio==0.13.1 torchmetrics==0.11.4 torchvision==0.14.1\n",
        "!pip install -q --upgrade gdown\n",
        "\n",
        "print(\"\\033[93mDone!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=\"ffc800\"> **Voice package generation section.** üó£Ô∏è\n",
        "#@markdown ---\n",
        "%cd /content/piper/src/python\n",
        "import os\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "from google.colab import output\n",
        "guideurl = \"https://github.com/rmcpantoja/piper/blob/master/notebooks/wav/en\"\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### *File selection method:*\n",
        "use_drive_picker = True #@param {type:\"boolean\"}\n",
        "#@markdown ‚Üë **Check to use Google Drive file picker** (easier), or uncheck to paste IDs/URLs manually.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### *Manual entry (only if file picker is disabled):*\n",
        "#@markdown **Drive ID or direct download link of the model:**\n",
        "model_id = \"\" #@param {type:\"string\"}\n",
        "#@markdown **Drive ID or direct download link of the config.json file:**\n",
        "config_id = \"\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### *Voice package settings:*\n",
        "#@markdown **Choose the language code (iso639-1 format):**\n",
        "#@markdown You can see a list of language codes and names [here](https://www.loc.gov/standards/iso639-2/php/English_list.php).\n",
        "\n",
        "language = \"en_US\" #@param [\"ar_JO\", \"ca_ES\", \"cs_CZ\", \"da_DK\", \"de_DE\", \"el_GR\", \"en_GB\", \"en_US\", \"es_ES\", \"es_LA\", \"fi_FI\", \"fr_FR\", \"grc\", \"hu_GU\", \"is_IS\", \"it_IT\", \"kk_KZ\", \"ka_GE\", \"lb_LU\", \"nb\", \"ne\", \"nl_BE\", \"no_NO\", \"pl_PL\", \"pt_BR\", \"pt_PT\", \"ro_RO\", \"ru_RU\", \"sk_SK\", \"sr\", \"sv_SE\", \"sw_CD\", \"tr_TR\", \"uk_UA\", \"vi_VN\", \"zh_CN\"]\n",
        "voice_name = \"\" #@param {type:\"string\"}\n",
        "voice_name = voice_name.lower()\n",
        "quality = \"medium\" #@param [\"high\", \"low\", \"medium\", \"x-low\"]\n",
        "#@markdown **Do you want to write a model card?** *(Optional.)*\n",
        "write_model_card = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **Do you want this voice to have a faster response speed?**\n",
        "streaming = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Store selected file paths globally\n",
        "selected_model_path = None\n",
        "selected_config_path = None\n",
        "\n",
        "def start_process(streaming):\n",
        "    if not os.path.exists(\"/content/project/model.ckpt\"):\n",
        "        raise Exception(\"Could not download model! Make sure the file is shareable to everyone.\")\n",
        "    output.eval_js(f'new Audio(\"{guideurl}/starting.wav?raw=true\").play()')\n",
        "    if not streaming:\n",
        "        !python -m piper_train.export_onnx \"/content/project/model.ckpt\" \"{export_voice_path}/{export_voice_name}.onnx\"\n",
        "    else:\n",
        "        !python -m piper_train.export_onnx_streaming \"/content/project/model.ckpt\" \"{export_voice_path}\"\n",
        "    print(\"\\033[93mCompressing...\")\n",
        "    !tar -czvf \"{packages_path}/{export_voice_name}.tar.gz\" -C \"{export_voice_path}\" .\n",
        "    output.eval_js(f'new Audio(\"{guideurl}/success.wav?raw=true\").play()')\n",
        "    print(\"\\033[93mDone!\")\n",
        "\n",
        "def download_from_id_or_url(file_id_or_url, output_path):\n",
        "    \"\"\"Download file from Drive ID or URL.\"\"\"\n",
        "    if file_id_or_url.startswith(\"1\"):\n",
        "        !gdown -q \"{file_id_or_url}\" -O \"{output_path}\"\n",
        "    elif file_id_or_url.startswith(\"https://drive.google.com/file/d/\"):\n",
        "        !gdown -q \"{file_id_or_url}\" -O \"{output_path}\" --fuzzy\n",
        "    else:\n",
        "        !wget -q \"{file_id_or_url}\" -O \"{output_path}\"\n",
        "\n",
        "def copy_from_drive(drive_path, output_path):\n",
        "    \"\"\"Copy file from mounted Drive path.\"\"\"\n",
        "    import shutil\n",
        "    shutil.copy(drive_path, output_path)\n",
        "\n",
        "if not streaming:\n",
        "    export_voice_name = f\"{language}-{voice_name}-{quality}\"\n",
        "else:\n",
        "    export_voice_name = f\"{language}-{voice_name}+RT-{quality}\"\n",
        "export_voice_path = \"/content/project/voice-\"+export_voice_name\n",
        "packages_path = \"/content/project/packages\"\n",
        "if not os.path.exists(export_voice_path):\n",
        "    os.makedirs(export_voice_path)\n",
        "if not os.path.exists(packages_path):\n",
        "    os.makedirs(packages_path)\n",
        "\n",
        "if use_drive_picker:\n",
        "    # Mount Google Drive and use file picker\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    print(\"\\n\\033[93m\" + \"=\"*50)\n",
        "    print(\"FILE PICKER MODE\")\n",
        "    print(\"=\"*50 + \"\\033[0m\\n\")\n",
        "    \n",
        "    # Create file picker widgets\n",
        "    from google.colab import files\n",
        "    import ipywidgets as widgets\n",
        "    from IPython.display import display, clear_output\n",
        "    \n",
        "    # File path input widgets\n",
        "    model_path_widget = widgets.Text(\n",
        "        value='',\n",
        "        placeholder='/content/drive/MyDrive/path/to/model.ckpt',\n",
        "        description='Model:',\n",
        "        layout=widgets.Layout(width='80%'),\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    config_path_widget = widgets.Text(\n",
        "        value='',\n",
        "        placeholder='/content/drive/MyDrive/path/to/config.json',\n",
        "        description='Config:',\n",
        "        layout=widgets.Layout(width='80%'),\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    # Browse buttons that open file browser\n",
        "    browse_model_btn = widgets.Button(description='Browse...', button_style='info')\n",
        "    browse_config_btn = widgets.Button(description='Browse...', button_style='info')\n",
        "    \n",
        "    # Output area for file browser\n",
        "    file_browser_output = widgets.Output()\n",
        "    \n",
        "    def create_file_browser(target_widget, file_filter=None):\n",
        "        \"\"\"Create an interactive file browser.\"\"\"\n",
        "        current_path = ['/content/drive/MyDrive']\n",
        "        \n",
        "        with file_browser_output:\n",
        "            clear_output()\n",
        "            \n",
        "            def list_directory(path):\n",
        "                items = []\n",
        "                try:\n",
        "                    for item in sorted(os.listdir(path)):\n",
        "                        full_path = os.path.join(path, item)\n",
        "                        if os.path.isdir(full_path):\n",
        "                            items.append(('üìÅ ' + item, full_path, True))\n",
        "                        elif file_filter is None or item.endswith(file_filter):\n",
        "                            items.append(('üìÑ ' + item, full_path, False))\n",
        "                except PermissionError:\n",
        "                    pass\n",
        "                return items\n",
        "            \n",
        "            def update_browser(path):\n",
        "                with file_browser_output:\n",
        "                    clear_output()\n",
        "                    current_path[0] = path\n",
        "                    \n",
        "                    # Header\n",
        "                    print(f\"\\033[93mCurrent: {path}\\033[0m\\n\")\n",
        "                    \n",
        "                    # Parent directory button\n",
        "                    if path != '/content/drive/MyDrive':\n",
        "                        parent_btn = widgets.Button(description='üìÅ ..', layout=widgets.Layout(width='auto'))\n",
        "                        parent_btn.on_click(lambda b: update_browser(os.path.dirname(path)))\n",
        "                        display(parent_btn)\n",
        "                    \n",
        "                    # List items\n",
        "                    items = list_directory(path)\n",
        "                    for display_name, full_path, is_dir in items:\n",
        "                        btn = widgets.Button(description=display_name, layout=widgets.Layout(width='auto'))\n",
        "                        if is_dir:\n",
        "                            btn.on_click(lambda b, p=full_path: update_browser(p))\n",
        "                        else:\n",
        "                            btn.style.button_color = 'lightgreen'\n",
        "                            def select_file(b, p=full_path):\n",
        "                                target_widget.value = p\n",
        "                                with file_browser_output:\n",
        "                                    clear_output()\n",
        "                                    print(f\"\\033[92m‚úì Selected: {p}\\033[0m\")\n",
        "                            btn.on_click(select_file)\n",
        "                        display(btn)\n",
        "                    \n",
        "                    # Cancel button\n",
        "                    cancel_btn = widgets.Button(description='Cancel', button_style='danger')\n",
        "                    cancel_btn.on_click(lambda b: clear_output())\n",
        "                    display(widgets.HTML('<br>'))\n",
        "                    display(cancel_btn)\n",
        "            \n",
        "            update_browser(current_path[0])\n",
        "    \n",
        "    browse_model_btn.on_click(lambda b: create_file_browser(model_path_widget, '.ckpt'))\n",
        "    browse_config_btn.on_click(lambda b: create_file_browser(config_path_widget, '.json'))\n",
        "    \n",
        "    # Start button\n",
        "    start_btn = widgets.Button(description='Start Export', button_style='success', \n",
        "                                layout=widgets.Layout(width='200px', height='40px'))\n",
        "    status_output = widgets.Output()\n",
        "    \n",
        "    def on_start_click(b):\n",
        "        with status_output:\n",
        "            clear_output()\n",
        "            model_path = model_path_widget.value.strip()\n",
        "            config_path = config_path_widget.value.strip()\n",
        "            \n",
        "            if not model_path or not config_path:\n",
        "                print(\"\\033[91m‚úó Please select both model and config files!\\033[0m\")\n",
        "                return\n",
        "            \n",
        "            if not os.path.exists(model_path):\n",
        "                print(f\"\\033[91m‚úó Model file not found: {model_path}\\033[0m\")\n",
        "                return\n",
        "            \n",
        "            if not os.path.exists(config_path):\n",
        "                print(f\"\\033[91m‚úó Config file not found: {config_path}\\033[0m\")\n",
        "                return\n",
        "            \n",
        "            print(\"\\033[93mCopying files...\\033[0m\")\n",
        "            copy_from_drive(model_path, \"/content/project/model.ckpt\")\n",
        "            copy_from_drive(config_path, f\"{export_voice_path}/{export_voice_name}.onnx.json\")\n",
        "            \n",
        "            # Handle streaming config modification\n",
        "            if streaming:\n",
        "                with open(f\"{export_voice_path}/{export_voice_name}.onnx.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "                    tmp = f.read()\n",
        "                new_config = json.loads(tmp)\n",
        "                new_config[\"streaming\"] = True\n",
        "                new_config[\"key\"] = export_voice_name\n",
        "                with open(f\"{export_voice_path}/{export_voice_name}.onnx.json\", \"w\", encoding=\"utf-8\") as f_new:\n",
        "                    json.dump(new_config, f_new, indent=4)\n",
        "            \n",
        "            # Handle model card if requested\n",
        "            if write_model_card:\n",
        "                with open(f\"{export_voice_path}/{export_voice_name}.onnx.json\", \"r\") as file:\n",
        "                    config = json.load(file)\n",
        "                sample_rate = config[\"audio\"][\"sample_rate\"]\n",
        "                num_speakers = config[\"num_speakers\"]\n",
        "                \n",
        "                model_card_text = f'# Model card for {voice_name} ({quality})\\n\\n* Language: {language}\\n* Speakers: {num_speakers}\\n* Quality: {quality}\\n* Samplerate: {sample_rate}Hz\\n\\n## Dataset\\n\\n* URL: \\n* License: \\n\\n## Training\\n\\nTrained from scratch.'\n",
        "                with open(f'{export_voice_path}/MODEL_CARD', 'w') as file:\n",
        "                    file.write(model_card_text)\n",
        "            \n",
        "            start_process(streaming)\n",
        "    \n",
        "    start_btn.on_click(on_start_click)\n",
        "    \n",
        "    # Display the UI\n",
        "    print(\"Select your model (.ckpt) and config (.json) files from Google Drive:\\n\")\n",
        "    display(widgets.HBox([model_path_widget, browse_model_btn]))\n",
        "    display(widgets.HBox([config_path_widget, browse_config_btn]))\n",
        "    display(file_browser_output)\n",
        "    display(widgets.HTML('<br>'))\n",
        "    display(start_btn)\n",
        "    display(status_output)\n",
        "\n",
        "else:\n",
        "    # Original manual ID/URL mode\n",
        "    print(\"\\033[93mDownloading model and config...\\033[0m\")\n",
        "    download_from_id_or_url(model_id, \"/content/project/model.ckpt\")\n",
        "    download_from_id_or_url(config_id, f\"{export_voice_path}/{export_voice_name}.onnx.json\")\n",
        "\n",
        "    if os.path.exists(f\"{export_voice_path}/{export_voice_name}.onnx.json\") and streaming:\n",
        "        with open(f\"{export_voice_path}/{export_voice_name}.onnx.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "            tmp = f.read()\n",
        "        new_config = json.loads(tmp)\n",
        "        new_config[\"streaming\"] = True\n",
        "        new_config[\"key\"] = export_voice_name\n",
        "\n",
        "        with open(f\"{export_voice_path}/{export_voice_name}.onnx.json\", \"w\", encoding=\"utf-8\") as f_new:\n",
        "            json.dump(new_config, f_new, indent=4)\n",
        "\n",
        "    if write_model_card:\n",
        "        with open(f\"{export_voice_path}/{export_voice_name}.onnx.json\", \"r\") as file:\n",
        "            config = json.load(file)\n",
        "        sample_rate = config[\"audio\"][\"sample_rate\"]\n",
        "        num_speakers = config[\"num_speakers\"]\n",
        "        output.eval_js(f'new Audio(\"{guideurl}/waiting.wav?raw=true\").play()')\n",
        "        text_area = widgets.Textarea(\n",
        "            description = \"Fill in this template and press Start to generate the voice package:\",\n",
        "            value=f'# Model card for {voice_name} ({quality})\\n\\n* Language: {language} (normalized)\\n* Speakers: {num_speakers}\\n* Quality: {quality}\\n* Samplerate: {sample_rate}Hz\\n\\n## Dataset\\n\\n* URL: \\n* License: \\n\\n## Training\\n\\nTrained from scratch.\\nOr finetuned from: ',\n",
        "            layout=widgets.Layout(width='500px', height='200px')\n",
        "        )\n",
        "        button = widgets.Button(description='Start')\n",
        "\n",
        "        def create_model_card(button):\n",
        "            model_card_text = text_area.value.strip()\n",
        "            with open(f'{export_voice_path}/MODEL_CARD', 'w') as file:\n",
        "                file.write(model_card_text)\n",
        "            text_area.close()\n",
        "            button.close()\n",
        "            output.clear()\n",
        "            start_process(streaming)\n",
        "\n",
        "        button.on_click(create_model_card)\n",
        "\n",
        "        display(text_area, button)\n",
        "    else:\n",
        "        start_process(streaming)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PqcoBb26V5xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=\"ffc800\"> **Download/export your generated voice package.** üì•\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #### *How do you want to export your model?*\n",
        "export_mode = \"upload it to my Google Drive\" #@param [\"Download the voice package on my device (may take some time)\", \"upload it to my Google Drive\"]\n",
        "print(\"\\033[93mExporting package...\")\n",
        "if export_mode == \"Download the voice package on my device (may take some time)\":\n",
        "    from google.colab import files\n",
        "    files.download(f\"{packages_path}/{export_voice_name}.tar.gz\")\n",
        "    msg = \"Please wait a moment while the package is being downloaded.\"\n",
        "else:\n",
        "    voicepacks_folder = \"/content/drive/MyDrive/piper voice packages\"\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    if not os.path.exists(voicepacks_folder):\n",
        "        os.makedirs(voicepacks_folder)\n",
        "    !cp \"{packages_path}/{export_voice_name}.tar.gz\" \"{voicepacks_folder}\"\n",
        "    msg = f\"You can find the generated voice package at: {voicepacks_folder}.\"\n",
        "print(f\"\\033[93mDone! {msg}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Hu3V9CJeWc4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \"*I want to test this model! I don't need anything else anymore?*\"\n",
        "\n",
        "No, this is almost the end! Now you can share your generated package to your friends, upload to a cloud storage and/or test it on:\n",
        "* [The inference notebook](https://colab.research.google.com/github/rmcpantoja/piper/blob/master/notebooks/piper_inference_(ONNX).ipynb)\n",
        "  * Run the cells in order for it to work correctly, as well as all the notebooks. Also, the inference notebook will guide you through the process using the enhanced accessibility feature if you wish. It's easy to use. Test it!\n",
        "* Or through the NVDA screen reader!\n",
        "  * Download and install the latest version of the [add-on](https://github.com/mush42/piper-nvda/releases).\n",
        "  * Once the add-on is installed, go to NVDA menu/piper voice manager...\n",
        "  * In the installed voices page, tab until you find the `Install from local file` button, press enter and select the generated package in your downloads.\n",
        "  * Once the package is selected and installed, apply the changes and restart NVDA to update the voice list.\n",
        "* Enjoy your creation!"
      ],
      "metadata": {
        "id": "IRiNBHkeoDbC"
      }
    }
  ]
}
